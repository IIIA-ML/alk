"""The machinery to conduct experiment with the `ExploitCandidatesIterator` to compare its gain to `TopDownIterator`'s gain"""

import logging
import os
from typing import List  # For type hints

import pandas as pd

from alk import cbr, common, rank
from alk.exp import exp_common


logger = logging.getLogger("ALK")


class ExpExploitData:

    def __init__(self):
        self.data = []

    def add(self, update, gain, iterator):
        """Adds experiment data.

        Args:
            update (int): the index of the sequence update
            gain (float): Percentage of gain in terms of avoided similarity calculations compared to a brute-force search
            iterator (str): iterator's name

        """
        self.data.append([update, gain, iterator])

    def process(self):
        """Returns dataframe w/o actual processing

        Returns:
            pd.DataFrame: columns -> ["update", "gain", "iterator"]

        """
        return pd.DataFrame(self.data, columns=["update", "gain", "iterator"])


class ExpExploitSettings:
    """Settings used in the "exploit candidates iteration" experiment.

    Attributes:
        dataset (str): Full path of the dataset "arff" file
        tw_width (int): if > 0, width of the 'moving' time window;
            otherwise, 'expanding' time window approach is applied.
        tw_step (int): number of steps (in terms of data points in TS) taken at each update.
            This can also be seen as the number of data points changed at each update.
        k (int): k of kNN
        test_size (float): (0., 1.) ratio of the time series dataset to be used as Test CB
        cb_size (int): Number of cases in the Train CB

    """
    def __init__(self, dataset, tw_width, tw_step, k, test_size, cb_size):
        """

        Args:
            dataset (str): Full path of the dataset "arff" file
            tw_width (int): if > 0, width of the 'moving' time window;
                otherwise, 'expanding' time window approach is applied.
            tw_step (int): number of steps (in terms of data points in TS) taken at each update.
                This can also be seen as the number of data points changed at each update.
            k (int): k of kNN
            test_size (float): (0., 1.) ratio of the time series dataset to be used as Test CB
            cb_size (int): Number of cases in the Train CB

        """
        # TODO (OM, 20200525): Move this part to a base class ExpCommonSettings and inherit it by all Exp~Settings
        self.dataset = dataset
        self.tw_width = tw_width
        self.tw_step = tw_step
        self.k = k
        self.test_size = test_size
        self.cb_size = cb_size


class ExpExploitOutput(exp_common.Output):
    """Holds and saves jumping iteration experiment settings and result data"""

    def __init__(self, settings, data):
        """Overrides the parent method only to specify type annotations.

        Args:
            settings (ExpExploitSettings):
            data (ExpExploitData):

        """
        # super().__init__(settings, data)  # commented to help IDE auto-fill below attributes
        self.settings = settings  # type: ExpExploitSettings
        self.data = data

    def save(self, out_file=None):
        """Saves the object itself into a pickle file.

        Args:
            out_file (str): Full path to the dumped pickle file.
                If not given, it is generated automatically out of experiment settings.

        Returns:
            str: Full path to the dumped pickle file

        """
        if out_file is None:
            out_file = gen_exploit_output_f_path(self.settings.dataset, self.settings.tw_width, self.settings.tw_step, self.settings.test_size)
        common.dump_obj(self, out_file)
        logger.info("Anytime Lazy KNN - Exploit Candidates experiment output dumped into '{}'.".format(out_file))
        return out_file


class ExpExploitEngine:
    """Jumping Iteration experiment engine"""

    def __init__(self, cb, k, similarity, test_size=0.01):
        """

        Args:
            cb (cbr.TCaseBase):
            k (int): k of kNN.
            similarity (Callable): a normalized similarity measure that should return a `float` in [0., 1.]
            test_size (float): ratio of the number of test sequences to be separated from the `cb`.

        """
        self.cb = cb
        self.k = k
        self.similarity = similarity
        self.test_size = test_size

        logger.info(" Exploit Candidates Iteration experiment engine created")

    def run(self):
        """Runs the  Exploit Candidates Iteration experiment.

        Returns:
            pd.DataFrame: Output of the `ExpExploitData.process()`
                columns -> ["update", "gain", "iterator"]

        """
        # Create an ExpExploitData instance to save experiment data
        exp_exploit_data = ExpExploitData()
        # Generate test problems
        CB_train, CB_test = exp_common.split_cb(self.cb, self.test_size)
        len_test = len(CB_test)
        CB_train = cbr.TCaseBase(cb=CB_train)  # This will be passed to Anytime Lazy KNN, not the `ExpInsightsEngine.cb`
        # Conduct tests for each sequence in cb_test
        for idx, sequence in enumerate(CB_test):
            logger.info(".. Testing with problem sequence {} of {} (seq_id: {})".format(idx + 1, len_test, sequence.seq_id))
            # For every problem create two sequence solvers, one for TopDown, others for ExploitCandidates Iterator
            top_down_solver = exp_common.SolveSequence(CB_train, self.k, sequence, self.similarity, rank.TopDownIterator())  # Note: 'exp_insights_raw' not provided
            exploit_solver = exp_common.SolveSequence(CB_train, self.k, sequence, self.similarity, rank.ExploitCandidatesIterator())
            # Run tests for each update
            for stop_update in range(sequence.n_profiles()):
                # Run top_down_solver to stop at the end of the stop_update
                logger.debug(".... TOP_DOWN_solver launching for stop_update: {}".format(stop_update))
                kNN_top_down, _, calc_pct_top_down = top_down_solver.solve(stop_update=stop_update)
                # Append to experiment data
                exp_exploit_data.add(stop_update, 100. - calc_pct_top_down, rank.TopDownIterator.abbrv)
                # Run exploit_cand_solver
                logger.debug(".... EXPLOIT_CANDIDATES_solver launching for stop_update: {}".format(stop_update))
                kNN_exploit, _, calc_pct_exploit = exploit_solver.solve(stop_update=stop_update)
                # Append to experiment data
                exp_exploit_data.add(stop_update, 100. - calc_pct_exploit, rank.ExploitCandidatesIterator.abbrv)
            # Help garbage collector to release the memory as soon as possible
            del top_down_solver
            del exploit_solver
        return exp_exploit_data.process()


def gen_exploit_output_f_path(dataset, tw_width, tw_step, k, test_size, suffix=""):
    """Returns full path of the output file for the exploit candidates experiment results"""
    # TODO (OM, 20200525): Implement a common function 'gen_exp_output_f_path' -> {prefix}_{d}_w_{w}_s_{s}_k_{k}_t_{t}{x}{e} and call it from its variants for each type of experiment
    dataset_name = os.path.splitext(os.path.basename(dataset))[0]  # Base file name w/o extension
    out_file = os.path.join(common.APP.FOLDER.RESULT,
                            "XCAND_{d}_w_{w}_s_{s}_k_{k}_t_{t}{x}{e}".format(
                                d=dataset_name, w=tw_width, s=tw_step, k=k, t=str(test_size), x=suffix, e=common.APP.FILE_EXT.PICKLE))
    return out_file
